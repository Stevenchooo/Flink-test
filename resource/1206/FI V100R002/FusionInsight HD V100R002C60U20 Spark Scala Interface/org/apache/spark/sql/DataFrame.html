<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>DataFrame - org.apache.spark.sql.DataFrame</title>
          <meta name="description" content="DataFrame - org.apache.spark.sql.DataFrame" />
          <meta name="keywords" content="DataFrame org.apache.spark.sql.DataFrame" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript">
         if(top === self) {
            var url = '../../../../index.html';
            var hash = 'org.apache.spark.sql.DataFrame';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="type">
      <div id="definition">
        <img src="../../../../lib/class_big.png" />
        <p id="owner"><a href="../../../package.html" class="extype" name="org">org</a>.<a href="../../package.html" class="extype" name="org.apache">apache</a>.<a href="../package.html" class="extype" name="org.apache.spark">spark</a>.<a href="package.html" class="extype" name="org.apache.spark.sql">sql</a></p>
        <h1>DataFrame</h1>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>:: Experimental ::
A distributed collection of data organized into named columns.</p><p>A <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> is equivalent to a relational table in Spark SQL. The following example creates
a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by pointing Spark SQL to a Parquet data set.</p><pre><span class="kw">val</span> people = sqlContext.read.parquet(<span class="lit">"..."</span>)  <span class="cmt">// in Scala</span>
DataFrame people = sqlContext.read().parquet(<span class="lit">"..."</span>)  <span class="cmt">// in Java</span></pre><p>Once created, it can be manipulated using the various domain-specific-language (DSL) functions
defined in: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> (this class), <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>, and <a href="functions$.html" class="extype" name="org.apache.spark.sql.functions">functions</a>.</p><p>To select a column from the data frame, use <code>apply</code> method in Scala and <code>col</code> in Java.</p><pre><span class="kw">val</span> ageCol = people(<span class="lit">"age"</span>)  <span class="cmt">// in Scala</span>
Column ageCol = people.col(<span class="lit">"age"</span>)  <span class="cmt">// in Java</span></pre><p>Note that the <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> type can also be manipulated through its various functions.</p><pre><span class="cmt">// The following creates a new column that increases everybody's age by 10.</span>
people(<span class="lit">"age"</span>) + <span class="num">10</span>  <span class="cmt">// in Scala</span>
people.col(<span class="lit">"age"</span>).plus(<span class="num">10</span>);  <span class="cmt">// in Java</span></pre><p>A more concrete example in Scala:</p><pre><span class="cmt">// To create DataFrame using SQLContext</span>
<span class="kw">val</span> people = sqlContext.read.parquet(<span class="lit">"..."</span>)
<span class="kw">val</span> department = sqlContext.read.parquet(<span class="lit">"..."</span>)

people.filter(<span class="lit">"age > 30"</span>)
  .join(department, people(<span class="lit">"deptId"</span>) === department(<span class="lit">"id"</span>))
  .groupBy(department(<span class="lit">"name"</span>), <span class="lit">"gender"</span>)
  .agg(avg(people(<span class="lit">"salary"</span>)), max(people(<span class="lit">"age"</span>)))</pre><p>and in Java:</p><pre><span class="cmt">// To create DataFrame using SQLContext</span>
DataFrame people = sqlContext.read().parquet(<span class="lit">"..."</span>);
DataFrame department = sqlContext.read().parquet(<span class="lit">"..."</span>);

people.filter(<span class="lit">"age"</span>.gt(<span class="num">30</span>))
  .join(department, people.col(<span class="lit">"deptId"</span>).equalTo(department(<span class="lit">"id"</span>)))
  .groupBy(department.col(<span class="lit">"name"</span>), <span class="lit">"gender"</span>)
  .agg(avg(people.col(<span class="lit">"salary"</span>)), max(people.col(<span class="lit">"age"</span>)));</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                <li class="group out"><span>Grouped</span></li>
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="org.apache.spark.sql.DataFrame"><span>DataFrame</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li>
            </ol>
            <a href="http://docs.scala-lang.org/overviews/scaladoc/usage.html#members" target="_blank">Learn more about member selection</a>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="org.apache.spark.sql.DataFrame#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(sqlContext:org.apache.spark.sql.SQLContext,logicalPlan:org.apache.spark.sql.catalyst.plans.logical.LogicalPlan):org.apache.spark.sql.DataFrame"></a>
      <a id="&lt;init&gt;:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="params">(<span name="sqlContext">sqlContext: <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></span>, <span name="logicalPlan">logicalPlan: <span class="extype" name="org.apache.spark.sql.catalyst.plans.logical.LogicalPlan">LogicalPlan</span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">A constructor that automatically analyzes the logical plan.</p><div class="fullcomment"><div class="comment cmt"><p>A constructor that automatically analyzes the logical plan.</p><p>This reports error eagerly as the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> is constructed, unless
<span class="extype" name="SQLConf.dataFrameEagerAnalysis">SQLConf.dataFrameEagerAnalysis</span> is turned off.
</p></div></div>
    </li></ol>
            </div>

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:AnyRef):Boolean"></a>
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:AnyRef):Boolean"></a>
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(expr:org.apache.spark.sql.Column,exprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Column,Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="expr">expr: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>, <span name="exprs">exprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><pre><span class="cmt">// df.agg(...) is a shorthand for df.groupBy().agg(...)</span>
df.agg(max($<span class="lit">"age"</span>), avg($<span class="lit">"salary"</span>))
df.groupBy().agg(max($<span class="lit">"age"</span>), avg($<span class="lit">"salary"</span>))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(exprs:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Java-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><pre><span class="cmt">// df.agg(...) is a shorthand for df.groupBy().agg(...)</span>
df.agg(<span class="std">Map</span>(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>))
df.groupBy().agg(<span class="std">Map</span>(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>))</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(exprs:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><pre><span class="cmt">// df.agg(...) is a shorthand for df.groupBy().agg(...)</span>
df.agg(<span class="std">Map</span>(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>))
df.groupBy().agg(<span class="std">Map</span>(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>))</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(aggExpr:(String,String),aggExprs:(String,String)*):org.apache.spark.sql.DataFrame"></a>
      <a id="agg((String,String),(String,String)*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="aggExpr">aggExpr: (<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)</span>, <span name="aggExprs">aggExprs: (<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><pre><span class="cmt">// df.agg(...) is a shorthand for df.groupBy().agg(...)</span>
df.agg(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>)
df.groupBy().agg(<span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>, <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#apply" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="apply(colName:String):org.apache.spark.sql.Column"></a>
      <a id="apply(String):Column"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">apply</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.
Note that the column name can also reference to a nested column like <code>a.b</code>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#as" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="as(alias:Symbol):org.apache.spark.sql.DataFrame"></a>
      <a id="as(Symbol):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">as</span><span class="params">(<span name="alias">alias: <span class="extype" name="scala.Symbol">Symbol</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#as" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="as(alias:String):org.apache.spark.sql.DataFrame"></a>
      <a id="as(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">as</span><span class="params">(<span name="alias">alias: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#cache" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="cache():DataFrame.this.type"></a>
      <a id="cache():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cache</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#coalesce" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="coalesce(numPartitions:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="coalesce(Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">coalesce</span><span class="params">(<span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.
Similar to coalesce defined on an <span class="extype" name="RDD">RDD</span>, this operation results in a narrow dependency, e.g.
if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of
the 100 new partitions will claim 10 of the current partitions.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#col" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="col(colName:String):org.apache.spark.sql.Column"></a>
      <a id="col(String):Column"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">col</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.
Note that the column name can also reference to a nested column like <code>a.b</code>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#collect" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="collect():Array[org.apache.spark.sql.Row]"></a>
      <a id="collect():Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collect</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns an array that contains all of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns an array that contains all of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#collectAsList" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="collectAsList():java.util.List[org.apache.spark.sql.Row]"></a>
      <a id="collectAsList():List[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collectAsList</span><span class="params">()</span><span class="result">: <span class="extype" name="java.util.List">List</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a Java list that contains all of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a Java list that contains all of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#columns" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="columns:Array[String]"></a>
      <a id="columns:Array[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">columns</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns all column names as an array.</p><div class="fullcomment"><div class="comment cmt"><p>Returns all column names as an array.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#count" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="count():Long"></a>
      <a id="count():Long"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">count</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Long">Long</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the number of rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the number of rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#cube" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="cube(col1:String,cols:String*):org.apache.spark.sql.GroupedData"></a>
      <a id="cube(String,String*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cube</span><span class="params">(<span name="col1">col1: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a multi-dimensional cube for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a multi-dimensional cube for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><p>This is a variant of cube that can only group by existing columns using column names
(i.e. cannot construct expressions).</p><pre><span class="cmt">// Compute the average for all numeric columns cubed by department and group.</span>
df.cube(<span class="lit">"department"</span>, <span class="lit">"group"</span>).avg()

<span class="cmt">// Compute the max age and average salary, cubed by department and gender.</span>
df.cube($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#cube" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="cube(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.GroupedData"></a>
      <a id="cube(Column*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cube</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a multi-dimensional cube for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a multi-dimensional cube for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><pre><span class="cmt">// Compute the average for all numeric columns cubed by department and group.</span>
df.cube($<span class="lit">"department"</span>, $<span class="lit">"group"</span>).avg()

<span class="cmt">// Compute the max age and average salary, cubed by department and gender.</span>
df.cube($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#describe" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="describe(cols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="describe(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">describe</span><span class="params">(<span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Computes statistics for numeric columns, including count, mean, stddev, min, and max.</p><div class="fullcomment"><div class="comment cmt"><p>Computes statistics for numeric columns, including count, mean, stddev, min, and max.
If no columns are given, this function computes statistics for all numerical columns.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>. If you want to
programmatically compute summary statistics, use the <code>agg</code> function instead.</p><pre>df.describe(<span class="lit">"age"</span>, <span class="lit">"height"</span>).show()

<span class="cmt">// output:</span>
<span class="cmt">// summary age   height</span>
<span class="cmt">// count   10.0  10.0</span>
<span class="cmt">// mean    53.3  178.05</span>
<span class="cmt">// stddev  11.6  15.7</span>
<span class="cmt">// min     18.0  163.0</span>
<span class="cmt">// max     92.0  192.0</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.1
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#distinct" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="distinct():org.apache.spark.sql.DataFrame"></a>
      <a id="distinct():DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">distinct</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.
This is an alias for <code>dropDuplicates</code>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#drop" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="drop(col:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="drop(Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">drop</span><span class="params">(<span name="col">col: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column dropped.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column dropped.
This version of drop accepts a Column rather than a name.
This is a no-op if the DataFrame doesn't have a column
with an equivalent expression.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.1
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#drop" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="drop(colName:String):org.apache.spark.sql.DataFrame"></a>
      <a id="drop(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">drop</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column dropped.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column dropped.
This is a no-op if schema doesn't contain column name.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#dropDuplicates" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="dropDuplicates(colNames:Array[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="dropDuplicates(Array[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropDuplicates</span><span class="params">(<span name="colNames">colNames: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with duplicate rows removed, considering only
the subset of columns.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with duplicate rows removed, considering only
the subset of columns.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#dropDuplicates" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="dropDuplicates(colNames:Seq[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="dropDuplicates(Seq[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropDuplicates</span><span class="params">(<span name="colNames">colNames: <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with duplicate rows removed, considering only
the subset of columns.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with duplicate rows removed, considering only
the subset of columns.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#dropDuplicates" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="dropDuplicates():org.apache.spark.sql.DataFrame"></a>
      <a id="dropDuplicates():DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropDuplicates</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.
This is an alias for <code>distinct</code>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#dtypes" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="dtypes:Array[(String,String)]"></a>
      <a id="dtypes:Array[(String,String)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dtypes</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[(<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns all column names and their data types as an array.</p><div class="fullcomment"><div class="comment cmt"><p>Returns all column names and their data types as an array.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#except" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="except(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="except(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">except</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows in this frame but not in another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows in this frame but not in another frame.
This is equivalent to <code>EXCEPT</code> in SQL.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#explain" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="explain():Unit"></a>
      <a id="explain():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explain</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Only prints the physical plan to the console for debugging purposes.</p><div class="fullcomment"><div class="comment cmt"><p>Only prints the physical plan to the console for debugging purposes.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#explain" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="explain(extended:Boolean):Unit"></a>
      <a id="explain(Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explain</span><span class="params">(<span name="extended">extended: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Prints the plans (logical and physical) to the console for debugging purposes.</p><div class="fullcomment"><div class="comment cmt"><p>Prints the plans (logical and physical) to the console for debugging purposes.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#explode" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="explode[A,B](inputColumn:String,outputColumn:String)(f:A=&gt;TraversableOnce[B])(implicitevidence$2:reflect.runtime.universe.TypeTag[B]):org.apache.spark.sql.DataFrame"></a>
      <a id="explode[A,B](String,String)((A)⇒TraversableOnce[B])(scala.reflect.api.JavaUniverse.TypeTag[B]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explode</span><span class="tparams">[<span name="A">A</span>, <span name="B">B</span>]</span><span class="params">(<span name="inputColumn">inputColumn: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="outputColumn">outputColumn: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.B">B</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.B">B</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where a single column has been expanded to zero
or more rows by the provided function.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where a single column has been expanded to zero
or more rows by the provided function.  This is similar to a <code>LATERAL VIEW</code> in HiveQL. All
columns of the input row are implicitly joined with each value that is output by the function.</p><pre>df.explode(<span class="lit">"words"</span>, <span class="lit">"word"</span>){words: <span class="std">String</span> <span class="kw">=&gt;</span> words.split(<span class="lit">" "</span>)}</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#explode" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="explode[A&lt;:Product](input:org.apache.spark.sql.Column*)(f:org.apache.spark.sql.Row=&gt;TraversableOnce[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame"></a>
      <a id="explode[A&lt;:Product](Column*)((Row)⇒TraversableOnce[A])(scala.reflect.api.JavaUniverse.TypeTag[A]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explode</span><span class="tparams">[<span name="A">A &lt;: <span class="extype" name="scala.Product">Product</span></span>]</span><span class="params">(<span name="input">input: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="params">(<span name="f">f: (<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where each row has been expanded to zero or more
rows by the provided function.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where each row has been expanded to zero or more
rows by the provided function.  This is similar to a <code>LATERAL VIEW</code> in HiveQL. The columns of
the input row are implicitly joined with each row that is output by the function.</p><p>The following example uses this function to count the number of books which contain
a given word:</p><pre><span class="kw">case</span> <span class="kw">class</span> Book(title: <span class="std">String</span>, words: <span class="std">String</span>)
<span class="kw">val</span> df: RDD[Book]

<span class="kw">case</span> <span class="kw">class</span> Word(word: <span class="std">String</span>)
<span class="kw">val</span> allWords = df.explode('words) {
  <span class="kw">case</span> Row(words: <span class="std">String</span>) <span class="kw">=&gt;</span> words.split(<span class="lit">" "</span>).map(Word(_))
}

<span class="kw">val</span> bookCountPerWord = allWords.groupBy(<span class="lit">"word"</span>).agg(countDistinct(<span class="lit">"title"</span>))</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#filter" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="filter(conditionExpr:String):org.apache.spark.sql.DataFrame"></a>
      <a id="filter(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="conditionExpr">conditionExpr: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given SQL expression.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given SQL expression.</p><pre>peopleDf.filter(<span class="lit">"age > 15"</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#filter" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="filter(condition:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="filter(Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="condition">condition: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given condition.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given condition.</p><pre><span class="cmt">// The following are equivalent:</span>
peopleDf.filter($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf.where($<span class="lit">"age"</span> &gt; <span class="num">15</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#first" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="first():org.apache.spark.sql.Row"></a>
      <a id="first():Row"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">first</span><span class="params">()</span><span class="result">: <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first row.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first row. Alias for head().</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#flatMap" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="flatMap[R](f:org.apache.spark.sql.Row=&gt;TraversableOnce[R])(implicitevidence$4:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="flatMap[R]((Row)⇒TraversableOnce[R])(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by first applying a function to all rows of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>,
and then flattening the results.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by first applying a function to all rows of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>,
and then flattening the results.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#foreach" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="foreach(f:org.apache.spark.sql.Row=&gt;Unit):Unit"></a>
      <a id="foreach((Row)⇒Unit):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreach</span><span class="params">(<span name="f">f: (<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>) ⇒ <span class="extype" name="scala.Unit">Unit</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Applies a function <code>f</code> to all rows.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a function <code>f</code> to all rows.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#foreachPartition" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="foreachPartition(f:Iterator[org.apache.spark.sql.Row]=&gt;Unit):Unit"></a>
      <a id="foreachPartition((Iterator[Row])⇒Unit):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreachPartition</span><span class="params">(<span name="f">f: (<span class="extype" name="scala.Iterator">Iterator</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]) ⇒ <span class="extype" name="scala.Unit">Unit</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Applies a function f to each partition of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a function f to each partition of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#groupBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="groupBy(col1:String,cols:String*):org.apache.spark.sql.GroupedData"></a>
      <a id="groupBy(String,String*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="params">(<span name="col1">col1: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><p>This is a variant of groupBy that can only group by existing columns using column names
(i.e. cannot construct expressions).</p><pre><span class="cmt">// Compute the average for all numeric columns grouped by department.</span>
df.groupBy(<span class="lit">"department"</span>).avg()

<span class="cmt">// Compute the max age and average salary, grouped by department and gender.</span>
df.groupBy($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#groupBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="groupBy(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.GroupedData"></a>
      <a id="groupBy(Column*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><pre><span class="cmt">// Compute the average for all numeric columns grouped by department.</span>
df.groupBy($<span class="lit">"department"</span>).avg()

<span class="cmt">// Compute the max age and average salary, grouped by department and gender.</span>
df.groupBy($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#head" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="head():org.apache.spark.sql.Row"></a>
      <a id="head():Row"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">head</span><span class="params">()</span><span class="result">: <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first row.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first row.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#head" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="head(n:Int):Array[org.apache.spark.sql.Row]"></a>
      <a id="head(Int):Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">head</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first <code>n</code> rows.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first <code>n</code> rows.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#inputFiles" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="inputFiles:Array[String]"></a>
      <a id="inputFiles:Array[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">inputFiles</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a best-effort snapshot of the files that compose this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a best-effort snapshot of the files that compose this DataFrame. This method simply
asks each constituent BaseRelation for its respective files and takes the union of all results.
Depending on the source relations, this may not find all input files. Duplicates are removed.
</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#intersect" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="intersect(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="intersect(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">intersect</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows only in both this frame and another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows only in both this frame and another frame.
This is equivalent to <code>INTERSECT</code> in SQL.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#isLocal" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="isLocal:Boolean"></a>
      <a id="isLocal:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isLocal</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
(without any Spark executors).</p><div class="fullcomment"><div class="comment cmt"><p>Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
(without any Spark executors).</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#javaRDD" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="javaRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row]"></a>
      <a id="javaRDD:JavaRDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">javaRDD</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#javaToPython" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="javaToPython:org.apache.spark.api.java.JavaRDD[Array[Byte]]"></a>
      <a id="javaToPython:JavaRDD[Array[Byte]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">javaToPython</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Byte">Byte</span>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Converts a JavaRDD to a PythonRDD.</p><div class="fullcomment"><div class="comment cmt"><p>Converts a JavaRDD to a PythonRDD.
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,joinExprs:org.apache.spark.sql.Column,joinType:String):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,Column,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="joinExprs">joinExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>, <span name="joinType">joinType: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><div class="fullcomment"><div class="comment cmt"><p>Join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression. The following performs
a full outer join between <code>df1</code> and <code>df2</code>.</p><pre><span class="cmt">// Scala:</span>
<span class="kw">import</span> org.apache.spark.sql.functions._
df1.join(df2, $<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>, <span class="lit">"outer"</span>)

<span class="cmt">// Java:</span>
<span class="kw">import</span> static org.apache.spark.sql.functions.*;
df1.join(df2, col(<span class="lit">"df1Key"</span>).equalTo(col(<span class="lit">"df2Key"</span>)), <span class="lit">"outer"</span>);</pre></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join.</p></dd><dt class="param">joinExprs</dt><dd class="cmt"><p>Join expression.</p></dd><dt class="param">joinType</dt><dd class="cmt"><p>One of: <code>inner</code>, <code>outer</code>, <code>left_outer</code>, <code>right_outer</code>, <code>leftsemi</code>.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,joinExprs:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="joinExprs">joinExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Inner join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><div class="fullcomment"><div class="comment cmt"><p>Inner join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><pre><span class="cmt">// The following two are equivalent:</span>
df1.join(df2, $<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>)
df1.join(df2).where($<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,usingColumns:Seq[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,Seq[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="usingColumns">usingColumns: <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Inner equi-join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the given columns.</p><div class="fullcomment"><div class="comment cmt"><p>Inner equi-join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the given columns.</p><p>Different from other join functions, the join columns will only appear once in the output,
i.e. similar to SQL's <code>JOIN USING</code> syntax.</p><pre><span class="cmt">// Joining df1 and df2 using the columns "user_id" and "user_name"</span>
df1.join(df2, <span class="std">Seq</span>(<span class="lit">"user_id"</span>, <span class="lit">"user_name"</span>))</pre><p>Note that if you perform a self-join using this function without aliasing the input
<a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>s, you will NOT be able to reference any columns after the join, since
there is no way to disambiguate which side of the join you would like to reference.
</p></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join operation.</p></dd><dt class="param">usingColumns</dt><dd class="cmt"><p>Names of the columns to join on. This columns must exist on both sides.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,usingColumn:String):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="usingColumn">usingColumn: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Inner equi-join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the given column.</p><div class="fullcomment"><div class="comment cmt"><p>Inner equi-join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the given column.</p><p>Different from other join functions, the join column will only appear once in the output,
i.e. similar to SQL's <code>JOIN USING</code> syntax.</p><pre><span class="cmt">// Joining df1 and df2 using the column "user_id"</span>
df1.join(df2, <span class="lit">"user_id"</span>)</pre><p>Note that if you perform a self-join using this function without aliasing the input
<a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>s, you will NOT be able to reference any columns after the join, since
there is no way to disambiguate which side of the join you would like to reference.
</p></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join operation.</p></dd><dt class="param">usingColumn</dt><dd class="cmt"><p>Name of the column to join on. This column must exist on both sides.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Cartesian join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Cartesian join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><p>Note that cartesian joins are very expensive without an extra filter that can be pushed down.
</p></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join operation.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#limit" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="limit(n:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="limit(Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">limit</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by taking the first <code>n</code> rows.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by taking the first <code>n</code> rows. The difference between this function
and <code>head</code> is that <code>head</code> returns an array while <code>limit</code> returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#logicalPlan" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logicalPlan:org.apache.spark.sql.catalyst.plans.logical.LogicalPlan"></a>
      <a id="logicalPlan:LogicalPlan"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">logicalPlan</span><span class="result">: <span class="extype" name="org.apache.spark.sql.catalyst.plans.logical.LogicalPlan">LogicalPlan</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#map" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="map[R](f:org.apache.spark.sql.Row=&gt;R)(implicitevidence$3:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="map[R]((Row)⇒R)(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>) ⇒ <span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by applying a function to all rows of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by applying a function to all rows of this DataFrame.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#mapPartitions" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="mapPartitions[R](f:Iterator[org.apache.spark.sql.Row]=&gt;Iterator[R])(implicitevidence$5:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="mapPartitions[R]((Iterator[Row])⇒Iterator[R])(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<span class="extype" name="scala.Iterator">Iterator</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]) ⇒ <span class="extype" name="scala.Iterator">Iterator</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by applying a function to each partition of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by applying a function to each partition of this DataFrame.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#na" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="na:org.apache.spark.sql.DataFrameNaFunctions"></a>
      <a id="na:DataFrameNaFunctions"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">na</span><span class="result">: <a href="DataFrameNaFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameNaFunctions">DataFrameNaFunctions</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a <a href="DataFrameNaFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameNaFunctions">DataFrameNaFunctions</a> for working with missing data.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <a href="DataFrameNaFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameNaFunctions">DataFrameNaFunctions</a> for working with missing data.</p><pre><span class="cmt">// Dropping rows containing any null values.</span>
df.na.drop()</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.1
</p></dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#numericColumns" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="numericColumns:Seq[org.apache.spark.sql.catalyst.expressions.Expression]"></a>
      <a id="numericColumns:Seq[Expression]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">numericColumns</span><span class="result">: <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.sql.catalyst.expressions.Expression">Expression</span>]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#orderBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="orderBy(sortExprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="orderBy(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">orderBy</span><span class="params">(<span name="sortExprs">sortExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.
This is an alias of the <code>sort</code> function.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#orderBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="orderBy(sortCol:String,sortCols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="orderBy(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">orderBy</span><span class="params">(<span name="sortCol">sortCol: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="sortCols">sortCols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.
This is an alias of the <code>sort</code> function.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#persist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="persist(newLevel:org.apache.spark.storage.StorageLevel):DataFrame.this.type"></a>
      <a id="persist(StorageLevel):DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">(<span name="newLevel">newLevel: <a href="../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#persist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="persist():DataFrame.this.type"></a>
      <a id="persist():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#printSchema" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="printSchema():Unit"></a>
      <a id="printSchema():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">printSchema</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Prints the schema to the console in a nice tree format.</p><div class="fullcomment"><div class="comment cmt"><p>Prints the schema to the console in a nice tree format.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#queryExecution" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="queryExecution:org.apache.spark.sql.SQLContext#QueryExecution"></a>
      <a id="queryExecution:QueryExecution"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">queryExecution</span><span class="result">: <a href="SQLContext$QueryExecution.html" class="extype" name="org.apache.spark.sql.SQLContext.QueryExecution">QueryExecution</a></span>
      </span>
      </h4>
      
    </li><li name="org.apache.spark.sql.DataFrame#randomSplit" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="randomSplit(weights:Array[Double]):Array[org.apache.spark.sql.DataFrame]"></a>
      <a id="randomSplit(Array[Double]):Array[DataFrame]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">randomSplit</span><span class="params">(<span name="weights">weights: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Double">Double</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Randomly splits this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with the provided weights.</p><div class="fullcomment"><div class="comment cmt"><p>Randomly splits this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with the provided weights.
</p></div><dl class="paramcmts block"><dt class="param">weights</dt><dd class="cmt"><p>weights for splits, will be normalized if they don't sum to 1.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#randomSplit" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="randomSplit(weights:Array[Double],seed:Long):Array[org.apache.spark.sql.DataFrame]"></a>
      <a id="randomSplit(Array[Double],Long):Array[DataFrame]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">randomSplit</span><span class="params">(<span name="weights">weights: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Double">Double</span>]</span>, <span name="seed">seed: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Randomly splits this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with the provided weights.</p><div class="fullcomment"><div class="comment cmt"><p>Randomly splits this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with the provided weights.
</p></div><dl class="paramcmts block"><dt class="param">weights</dt><dd class="cmt"><p>weights for splits, will be normalized if they don't sum to 1.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>Seed for sampling.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#rdd" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="rdd:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]"></a>
      <a id="rdd:RDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">lazy val</span>
      </span>
      <span class="symbol">
        <span class="name">rdd</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Represents the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as an <span class="extype" name="RDD">RDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>Represents the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as an <span class="extype" name="RDD">RDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s. Note that the RDD is
memoized. Once called, it won't change even if you change any query planning related Spark SQL
configurations (e.g. <code>spark.sql.shuffle.partitions</code>).</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#registerTempTable" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="registerTempTable(tableName:String):Unit"></a>
      <a id="registerTempTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">registerTempTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Registers this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a temporary table using the given name.</p><div class="fullcomment"><div class="comment cmt"><p>Registers this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a temporary table using the given name.  The lifetime of this
temporary table is tied to the <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a> that was used to create this DataFrame.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#repartition" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="repartition(numPartitions:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="repartition(Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">repartition</span><span class="params">(<span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#resolve" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="resolve(colName:String):org.apache.spark.sql.catalyst.expressions.NamedExpression"></a>
      <a id="resolve(String):NamedExpression"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">resolve</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.catalyst.expressions.NamedExpression">NamedExpression</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#rollup" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="rollup(col1:String,cols:String*):org.apache.spark.sql.GroupedData"></a>
      <a id="rollup(String,String*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rollup</span><span class="params">(<span name="col1">col1: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a multi-dimensional rollup for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a multi-dimensional rollup for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><p>This is a variant of rollup that can only group by existing columns using column names
(i.e. cannot construct expressions).</p><pre><span class="cmt">// Compute the average for all numeric columns rolluped by department and group.</span>
df.rollup(<span class="lit">"department"</span>, <span class="lit">"group"</span>).avg()

<span class="cmt">// Compute the max age and average salary, rolluped by department and gender.</span>
df.rollup($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#rollup" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="rollup(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.GroupedData"></a>
      <a id="rollup(Column*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rollup</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a multi-dimensional rollup for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a multi-dimensional rollup for the current <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns,
so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><pre><span class="cmt">// Compute the average for all numeric columns rolluped by department and group.</span>
df.rollup($<span class="lit">"department"</span>, $<span class="lit">"group"</span>).avg()

<span class="cmt">// Compute the max age and average salary, rolluped by department and gender.</span>
df.rollup($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sample" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sample(withReplacement:Boolean,fraction:Double):org.apache.spark.sql.DataFrame"></a>
      <a id="sample(Boolean,Double):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sample</span><span class="params">(<span name="withReplacement">withReplacement: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="fraction">fraction: <span class="extype" name="scala.Double">Double</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows, using a random seed.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows, using a random seed.
</p></div><dl class="paramcmts block"><dt class="param">withReplacement</dt><dd class="cmt"><p>Sample with replacement or not.</p></dd><dt class="param">fraction</dt><dd class="cmt"><p>Fraction of rows to generate.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sample" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sample(withReplacement:Boolean,fraction:Double,seed:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="sample(Boolean,Double,Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sample</span><span class="params">(<span name="withReplacement">withReplacement: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="fraction">fraction: <span class="extype" name="scala.Double">Double</span></span>, <span name="seed">seed: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows.
</p></div><dl class="paramcmts block"><dt class="param">withReplacement</dt><dd class="cmt"><p>Sample with replacement or not.</p></dd><dt class="param">fraction</dt><dd class="cmt"><p>Fraction of rows to generate.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>Seed for sampling.</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#schema" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="schema:org.apache.spark.sql.types.StructType"></a>
      <a id="schema:StructType"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">schema</span><span class="result">: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the schema of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the schema of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#select" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="select(col:String,cols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="select(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">select</span><span class="params">(<span name="col">col: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of columns.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of columns. This is a variant of <code>select</code> that can only select
existing columns using column names (i.e. cannot construct expressions).</p><pre><span class="cmt">// The following two are equivalent:</span>
df.select(<span class="lit">"colA"</span>, <span class="lit">"colB"</span>)
df.select($<span class="lit">"colA"</span>, $<span class="lit">"colB"</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#select" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="select(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="select(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">select</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of column based expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of column based expressions.</p><pre>df.select($<span class="lit">"colA"</span>, $<span class="lit">"colB"</span> + <span class="num">1</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#selectExpr" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="selectExpr(exprs:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="selectExpr(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">selectExpr</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of SQL expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of SQL expressions. This is a variant of <code>select</code> that accepts
SQL expressions.</p><pre>df.selectExpr(<span class="lit">"colA"</span>, <span class="lit">"colB as newName"</span>, <span class="lit">"abs(colC)"</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="show(numRows:Int,truncate:Boolean):Unit"></a>
      <a id="show(Int,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">(<span name="numRows">numRows: <span class="extype" name="scala.Int">Int</span></span>, <span name="truncate">truncate: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p><div class="fullcomment"><div class="comment cmt"><p>Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form. For example:</p><pre>year  month AVG('Adj Close) MAX('Adj Close)
<span class="num">1980</span>  <span class="num">12</span>    <span class="num">0.503218</span>        <span class="num">0.595103</span>
<span class="num">1981</span>  <span class="num">01</span>    <span class="num">0.523289</span>        <span class="num">0.570307</span>
<span class="num">1982</span>  <span class="num">02</span>    <span class="num">0.436504</span>        <span class="num">0.475256</span>
<span class="num">1983</span>  <span class="num">03</span>    <span class="num">0.410516</span>        <span class="num">0.442194</span>
<span class="num">1984</span>  <span class="num">04</span>    <span class="num">0.450090</span>        <span class="num">0.483521</span></pre></div><dl class="paramcmts block"><dt class="param">numRows</dt><dd class="cmt"><p>Number of rows to show</p></dd><dt class="param">truncate</dt><dd class="cmt"><p>Whether truncate long strings. If true, strings more than 20 characters will
             be truncated and all cells will be aligned right
</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.5.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="show(truncate:Boolean):Unit"></a>
      <a id="show(Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">(<span name="truncate">truncate: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the top 20 rows of <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p><div class="fullcomment"><div class="comment cmt"><p>Displays the top 20 rows of <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.
</p></div><dl class="paramcmts block"><dt class="param">truncate</dt><dd class="cmt"><p>Whether truncate long strings. If true, strings more than 20 characters will
             be truncated and all cells will be aligned right
</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.5.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="show():Unit"></a>
      <a id="show():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the top 20 rows of <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p><div class="fullcomment"><div class="comment cmt"><p>Displays the top 20 rows of <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form. Strings more than 20 characters
will be truncated, and all cells will be aligned right.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="show(numRows:Int):Unit"></a>
      <a id="show(Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">(<span name="numRows">numRows: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p><div class="fullcomment"><div class="comment cmt"><p>Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form. Strings more than 20 characters will be
truncated, and all cells will be aligned right. For example:</p><pre>year  month AVG('Adj Close) MAX('Adj Close)
<span class="num">1980</span>  <span class="num">12</span>    <span class="num">0.503218</span>        <span class="num">0.595103</span>
<span class="num">1981</span>  <span class="num">01</span>    <span class="num">0.523289</span>        <span class="num">0.570307</span>
<span class="num">1982</span>  <span class="num">02</span>    <span class="num">0.436504</span>        <span class="num">0.475256</span>
<span class="num">1983</span>  <span class="num">03</span>    <span class="num">0.410516</span>        <span class="num">0.442194</span>
<span class="num">1984</span>  <span class="num">04</span>    <span class="num">0.450090</span>        <span class="num">0.483521</span></pre></div><dl class="paramcmts block"><dt class="param">numRows</dt><dd class="cmt"><p>Number of rows to show
</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sort" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sort(sortExprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="sort(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sort</span><span class="params">(<span name="sortExprs">sortExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions. For example:</p><pre>df.sort($<span class="lit">"col1"</span>, $<span class="lit">"col2"</span>.desc)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sort" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sort(sortCol:String,sortCols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="sort(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sort</span><span class="params">(<span name="sortCol">sortCol: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="sortCols">sortCols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the specified column, all in ascending order.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the specified column, all in ascending order.</p><pre><span class="cmt">// The following 3 are equivalent</span>
df.sort(<span class="lit">"sortcol"</span>)
df.sort($<span class="lit">"sortcol"</span>)
df.sort($<span class="lit">"sortcol"</span>.asc)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sqlContext" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sqlContext:org.apache.spark.sql.SQLContext"></a>
      <a id="sqlContext:SQLContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sqlContext</span><span class="result">: <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></span>
      </span>
      </h4>
      
    </li><li name="org.apache.spark.sql.DataFrame#stat" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="stat:org.apache.spark.sql.DataFrameStatFunctions"></a>
      <a id="stat:DataFrameStatFunctions"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stat</span><span class="result">: <a href="DataFrameStatFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameStatFunctions">DataFrameStatFunctions</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a <a href="DataFrameStatFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameStatFunctions">DataFrameStatFunctions</a> for working statistic functions support.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <a href="DataFrameStatFunctions.html" class="extype" name="org.apache.spark.sql.DataFrameStatFunctions">DataFrameStatFunctions</a> for working statistic functions support.</p><pre><span class="cmt">// Finding frequent items in column with name 'a'.</span>
df.stat.freqItems(<span class="std">Seq</span>(<span class="lit">"a"</span>))</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#take" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="take(n:Int):Array[org.apache.spark.sql.Row]"></a>
      <a id="take(Int):Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">take</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first <code>n</code> rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first <code>n</code> rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toDF" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="toDF(colNames:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="toDF(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toDF</span><span class="params">(<span name="colNames">colNames: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with columns renamed.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with columns renamed. This can be quite convenient in conversion
from a RDD of tuples into a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with meaningful names. For example:</p><pre><span class="kw">val</span> rdd: RDD[(<span class="std">Int</span>, <span class="std">String</span>)] = ...
rdd.toDF()  <span class="cmt">// this implicit conversion creates a DataFrame with column name _1 and _2</span>
rdd.toDF(<span class="lit">"id"</span>, <span class="lit">"name"</span>)  <span class="cmt">// this creates a DataFrame with column name "id" and "name"</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toDF" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="toDF():org.apache.spark.sql.DataFrame"></a>
      <a id="toDF():DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toDF</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the object itself.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the object itself.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toJSON" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="toJSON:org.apache.spark.rdd.RDD[String]"></a>
      <a id="toJSON:RDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toJSON</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a RDD of JSON strings.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a RDD of JSON strings.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toJavaRDD" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="toJavaRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row]"></a>
      <a id="toJavaRDD:JavaRDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toJavaRDD</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#unionAll" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="unionAll(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="unionAll(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unionAll</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing union of rows in this frame and another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing union of rows in this frame and another frame.
This is equivalent to <code>UNION ALL</code> in SQL.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#unpersist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="unpersist():DataFrame.this.type"></a>
      <a id="unpersist():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unpersist</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#unpersist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="unpersist(blocking:Boolean):DataFrame.this.type"></a>
      <a id="unpersist(Boolean):DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unpersist</span><span class="params">(<span name="blocking">blocking: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#where" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="where(conditionExpr:String):org.apache.spark.sql.DataFrame"></a>
      <a id="where(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">where</span><span class="params">(<span name="conditionExpr">conditionExpr: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given SQL expression.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given SQL expression.</p><pre>peopleDf.where(<span class="lit">"age > 15"</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.5.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#where" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="where(condition:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="where(Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">where</span><span class="params">(<span name="condition">condition: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given condition.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given condition. This is an alias for <code>filter</code>.</p><pre><span class="cmt">// The following are equivalent:</span>
peopleDf.filter($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf.where($<span class="lit">"age"</span> &gt; <span class="num">15</span>)</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#withColumn" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="withColumn(colName:String,col:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="withColumn(String,Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">withColumn</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="col">col: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by adding a column or replacing the existing column that has
the same name.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by adding a column or replacing the existing column that has
the same name.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#withColumnRenamed" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="withColumnRenamed(existingName:String,newName:String):org.apache.spark.sql.DataFrame"></a>
      <a id="withColumnRenamed(String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">withColumnRenamed</span><span class="params">(<span name="existingName">existingName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="newName">newName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column renamed.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column renamed.
This is a no-op if schema doesn't contain existingName.</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.3.0
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#write" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="write:org.apache.spark.sql.DataFrameWriter"></a>
      <a id="write:DataFrameWriter"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">write</span><span class="result">: <a href="DataFrameWriter.html" class="extype" name="org.apache.spark.sql.DataFrameWriter">DataFrameWriter</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Interface for saving the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> out into external storage.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Interface for saving the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> out into external storage.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0
</p></dd></dl></div>
    </li></ol>
            </div>

        

        <div id="values" class="values members">
              <h3>Deprecated Value Members</h3>
              <ol><li name="org.apache.spark.sql.DataFrame#createJDBCTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="createJDBCTable(url:String,table:String,allowExisting:Boolean):Unit"></a>
      <a id="createJDBCTable(String,String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.jdbc()">createJDBCTable</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> to a JDBC database at <code>url</code> under the table name <code>table</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Save this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> to a JDBC database at <code>url</code> under the table name <code>table</code>.
This will run a <code>CREATE TABLE</code> and a bunch of <code>INSERT INTO</code> statements.
If you pass <code>true</code> for <code>allowExisting</code>, it will drop any table with the
given name; if you pass <code>false</code>, it will throw if the table already
exists.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.jdbc()</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#insertInto" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertInto(tableName:String):Unit"></a>
      <a id="insertInto(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.mode(SaveMode.Append).saveAsTable(tableName)">insertInto</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Adds the rows from this RDD to the specified table.</p><div class="fullcomment"><div class="comment cmt"><p>Adds the rows from this RDD to the specified table.
Throws an exception if the table already exists.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.mode(SaveMode.Append).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#insertInto" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertInto(tableName:String,overwrite:Boolean):Unit"></a>
      <a id="insertInto(String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.mode(SaveMode.Append|SaveMode.Overwrite).saveAsTable(tableName)">insertInto</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="overwrite">overwrite: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Adds the rows from this RDD to the specified table, optionally overwriting the existing data.</p><div class="fullcomment"><div class="comment cmt"><p>Adds the rows from this RDD to the specified table, optionally overwriting the existing data.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.mode(SaveMode.Append|SaveMode.Overwrite).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#insertIntoJDBC" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertIntoJDBC(url:String,table:String,overwrite:Boolean):Unit"></a>
      <a id="insertIntoJDBC(String,String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.jdbc()">insertIntoJDBC</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="overwrite">overwrite: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> to a JDBC database at <code>url</code> under the table name <code>table</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Save this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> to a JDBC database at <code>url</code> under the table name <code>table</code>.
Assumes the table already exists and has a compatible schema.  If you
pass <code>true</code> for <code>overwrite</code>, it will <code>TRUNCATE</code> the table before
performing the <code>INSERT</code>s.</p><p>The table must already exist on the database.  It must have a schema
that is compatible with the schema of this RDD; inserting the rows of
the RDD in order via the simple statement
<code>INSERT INTO table VALUES (?, ?, ..., ?)</code> should not fail.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.jdbc()</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(source:String,mode:org.apache.spark.sql.SaveMode,options:Map[String,String]):Unit"></a>
      <a id="save(String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).options(options).save()">save</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific)
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific)
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).options(options).save()</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(source:String,mode:org.apache.spark.sql.SaveMode,options:java.util.Map[String,String]):Unit"></a>
      <a id="save(String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).options(options).save()">save</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).options(options).save()</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,source:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="save(String,String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).save(path)">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this DataFrame to the given path based on the given data source and
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this DataFrame to the given path based on the given data source and
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).save(path)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,source:String):Unit"></a>
      <a id="save(String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).save(path)">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this DataFrame to the given path based on the given data source,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this DataFrame to the given path based on the given data source,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).save(path)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="save(String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.mode(mode).save(path)">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this DataFrame to the given path and <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode,
using the default data source configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this DataFrame to the given path and <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode,
using the default data source configured by spark.sql.sources.default.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.mode(mode).save(path)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String):Unit"></a>
      <a id="save(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.save(path)">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this DataFrame to the given path,
using the default data source configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this DataFrame to the given path,
using the default data source configured by spark.sql.sources.default and
<span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.save(path)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsParquetFile" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsParquetFile(path:String):Unit"></a>
      <a id="saveAsParquetFile(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.parquet(path)">saveAsParquetFile</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a parquet file, preserving the schema.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a parquet file, preserving the schema.
Files that are written out using this method can be read back in as a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>
using the <code>parquetFile</code> function in <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.parquet(path)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode,options:Map[String,String]):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).options(options).saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific)
Creates a table from the the contents of this DataFrame based on a given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific)
Creates a table from the the contents of this DataFrame based on a given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).options(options).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode,options:java.util.Map[String,String]):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).options(options).saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).options(options).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).mode(mode).saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).mode(mode).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String):Unit"></a>
      <a id="saveAsTable(String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.format(source).saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a table at the given path from the the contents of this DataFrame
based on a given data source and a set of options,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a table at the given path from the the contents of this DataFrame
based on a given data source and a set of options,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.format(source).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="saveAsTable(String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.mode(mode).saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a table from the the contents of this DataFrame, using the default data source
configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a table from the the contents of this DataFrame, using the default data source
configured by spark.sql.sources.default and <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.mode(mode).saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String):Unit"></a>
      <a id="saveAsTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use write.saveAsTable(tableName)">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Creates a table from the the contents of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a table from the the contents of this DataFrame.
It will use the default data source configured by spark.sql.sources.default.
This will fail if the table already exists.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p><p>When the DataFrame is created from a non-partitioned <span class="extype" name="HadoopFsRelation">HadoopFsRelation</span> with a single input
path, and the data source provider can be mapped to an existing Hive builtin SerDe (i.e. ORC
and Parquet), the table is persisted in a Hive compatible format, which means other systems
like Hive will be able to read this table. Otherwise, the table is persisted in a Spark SQL
specific format.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use write.saveAsTable(tableName)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toSchemaRDD" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toSchemaRDD:org.apache.spark.sql.DataFrame"></a>
      <a id="toSchemaRDD:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) use toDF">toSchemaRDD</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> use toDF</p></dd></dl></div>
    </li></ol>
            </div>
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="action">
              <h3>Actions</h3>
              
            </div><div class="group" name="basic">
              <h3>Basic DataFrame functions</h3>
              
            </div><div class="group" name="dfops">
              <h3>Language Integrated Queries</h3>
              
            </div><div class="group" name="output">
              <h3>Output Operations</h3>
              
            </div><div class="group" name="rdd">
              <h3>RDD Operations</h3>
              
            </div><div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
      <script defer="defer" type="text/javascript" id="jquery-js" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" id="jquery-ui-js" src="../../../../lib/jquery-ui.js"></script><script defer="defer" type="text/javascript" id="tools-tooltip-js" src="../../../../lib/tools.tooltip.js"></script><script defer="defer" type="text/javascript" id="template-js" src="../../../../lib/template.js"></script>
    </body>
      </html>